{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from rouge import Rouge\n",
    "import re\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "import six\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"加载数据\n",
    "    返回：[(text, summary)]\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            l = json.loads(l)\n",
    "            text = '\\n'.join([d['sentence'] for d in l['text']])\n",
    "            D.append((text, l['summary']))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow(inputs):\n",
    "    text, summary = inputs\n",
    "    texts = text_split(text, True)  # 取后maxlen句\n",
    "    summaries = text_split(summary, False)\n",
    "    mapping = extract_matching(texts, summaries)\n",
    "    labels = sorted(set([i[1] for i in mapping]))\n",
    "    pred_summary = ''.join([texts[i] for i in labels])\n",
    "    metric = compute_main_metric(pred_summary, summary)\n",
    "    return texts, labels, summary, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指标名\n",
    "metric_keys = ['main', 'rouge-1', 'rouge-2', 'rouge-l']\n",
    "\n",
    "# 计算rouge用\n",
    "rouge = Rouge()\n",
    "\n",
    "def compute_rouge(source, target, unit='word'):\n",
    "    \"\"\"计算rouge-1、rouge-2、rouge-l\n",
    "    \"\"\"\n",
    "    if unit == 'word':\n",
    "        source = jieba.cut(source, HMM=False)\n",
    "        #HMM: 是否使用隐式马尔科夫\n",
    "        target = jieba.cut(target, HMM=False)\n",
    "    source, target = ' '.join(source), ' '.join(target)\n",
    "    try:\n",
    "        scores = rouge.get_scores(hyps=source, refs=target)\n",
    "        return {\n",
    "            'rouge-1': scores[0]['rouge-1']['f'],\n",
    "            'rouge-2': scores[0]['rouge-2']['f'],\n",
    "            'rouge-l': scores[0]['rouge-l']['f'],\n",
    "        }\n",
    "    except ValueError:\n",
    "        return {\n",
    "            'rouge-1': 0.0,\n",
    "            'rouge-2': 0.0,\n",
    "            'rouge-l': 0.0,\n",
    "        }\n",
    "    \n",
    "def compute_main_metric(source, target, unit='word'):\n",
    "    \"\"\"计算所有metrics\n",
    "    \"\"\"\n",
    "    metrics = compute_rouge(source, target, unit)\n",
    "    metrics['main'] = (\n",
    "        metrics['rouge-1'] * 0.2 + metrics['rouge-2'] * 0.4 +\n",
    "        metrics['rouge-l'] * 0.4\n",
    "    )\n",
    "    return metrics['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(text, limited=True):\n",
    "    \"\"\"将长句按照标点分割为多个子句。\n",
    "    \"\"\"\n",
    "    texts = re.split('[\\n。；：，]',text)\n",
    "    texts = [x for x in texts if len(x)>0]\n",
    "    if limited:\n",
    "        texts = texts[-256:]\n",
    "    return texts\n",
    "\n",
    "def extract_matching(texts, summaries, start_i=0, start_j=0):\n",
    "    \"\"\"在texts中找若干句子，使得它们连起来与summaries尽可能相似\n",
    "    算法：texts和summaries都分句，然后找出summaries最长的句子，在texts\n",
    "          中找与之最相似的句子作为匹配，剩下部分递归执行。\n",
    "    \"\"\"\n",
    "    if len(texts) == 0 or len(summaries) == 0:\n",
    "        return []\n",
    "    i = np.argmax([len(s) for s in summaries])\n",
    "    j = np.argmax([compute_main_metric(t, summaries[i], 'char') for t in texts])\n",
    "    lm = extract_matching(texts[:j + 1], summaries[:i], start_i, start_j)\n",
    "    rm = extract_matching(\n",
    "        texts[j:], summaries[i + 1:], start_i + i + 1, start_j + j\n",
    "    )\n",
    "    return lm + [(start_i + i, start_j + j)] + rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    \"\"\"分句，并转换为抽取式摘要\n",
    "    \"\"\"\n",
    "    D = parallel_apply(\n",
    "        func=extract_flow,\n",
    "        iterable=tqdm(data, desc=u'转换数据'),\n",
    "        workers=10,\n",
    "        max_queue_size=200\n",
    "    )\n",
    "    total_metric = sum([d[3] for d in D])\n",
    "    D = [d[:3] for d in D]\n",
    "    print(u'抽取结果的平均指标: %s' % (total_metric / len(D)))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_apply(\n",
    "    func,\n",
    "    iterable,\n",
    "    workers,\n",
    "    max_queue_size,\n",
    "    callback=None,\n",
    "    dummy=False,\n",
    "    random_seeds=True\n",
    "):\n",
    "    \"\"\"多进程或多线程地将func应用到iterable的每个元素中。\n",
    "    注意这个apply是异步且无序的，也就是说依次输入a,b,c，但是\n",
    "    输出可能是func(c), func(a), func(b)。\n",
    "    参数：\n",
    "        callback: 处理单个输出的回调函数；\n",
    "        dummy: False是多进程/线性，True则是多线程/线性；\n",
    "        random_seeds: 每个进程的随机种子。\n",
    "    \"\"\"\n",
    "    if dummy:\n",
    "        from multiprocessing.dummy import Pool, Queue\n",
    "    else:\n",
    "        from multiprocessing import Pool, Queue\n",
    "\n",
    "    in_queue, out_queue, seed_queue = Queue(max_queue_size), Queue(), Queue()\n",
    "    if random_seeds is True:\n",
    "        random_seeds = [None] * workers\n",
    "    elif random_seeds is None or random_seeds is False:\n",
    "        random_seeds = []\n",
    "    for seed in random_seeds:\n",
    "        seed_queue.put(seed)\n",
    "\n",
    "    def worker_step(in_queue, out_queue):\n",
    "        \"\"\"单步函数包装成循环执行\n",
    "        \"\"\"\n",
    "        if not seed_queue.empty():\n",
    "            np.random.seed(seed_queue.get())\n",
    "        while True:\n",
    "            i, d = in_queue.get()\n",
    "            r = func(d)\n",
    "            out_queue.put((i, r))\n",
    "\n",
    "    # 启动多进程/线程\n",
    "    pool = Pool(workers, worker_step, (in_queue, out_queue))\n",
    "\n",
    "    if callback is None:\n",
    "        results = []\n",
    "\n",
    "    # 后处理函数\n",
    "    def process_out_queue():\n",
    "        out_count = 0\n",
    "        for _ in range(out_queue.qsize()):\n",
    "            i, d = out_queue.get()\n",
    "            out_count += 1\n",
    "            if callback is None:\n",
    "                results.append((i, d))\n",
    "            else:\n",
    "                callback(d)\n",
    "        return out_count\n",
    "\n",
    "    # 存入数据，取出结果\n",
    "    in_count, out_count = 0, 0\n",
    "    for i, d in enumerate(iterable):\n",
    "        in_count += 1\n",
    "        while True:\n",
    "            try:\n",
    "                in_queue.put((i, d), block=False)\n",
    "                break\n",
    "            except six.moves.queue.Full:\n",
    "                out_count += process_out_queue()\n",
    "        if in_count % max_queue_size == 0:\n",
    "            out_count += process_out_queue()\n",
    "\n",
    "    while out_count != in_count:\n",
    "        out_count += process_out_queue()\n",
    "\n",
    "    pool.terminate()\n",
    "\n",
    "    if callback is None:\n",
    "        results = sorted(results, key=lambda r: r[0])\n",
    "        return [r[1] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换数据:   5%|▌         | 210/4047 [00:00<00:01, 2084.73it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.856 seconds.\n",
      "Loading model cost 0.855 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.831 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.830 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.839 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.878 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.861 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.831 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.853 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Loading model cost 0.874 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "转换数据: 100%|██████████| 4047/4047 [03:11<00:00, 21.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取结果的平均指标: 0.6101703696853493\n",
      "输入数据：./sfzy_small.json\n",
      "数据顺序：./sfzy_small_random_order.json\n",
      "输出路径：./sfzy_small_extract.json\n"
     ]
    }
   ],
   "source": [
    "data_json = './sfzy_small.json'\n",
    "\n",
    "data_random_order_json = data_json[:-5] + '_random_order.json'\n",
    "data_extract_json = data_json[:-5] + '_extract.json'\n",
    "\n",
    "data = load_data(data_json)\n",
    "data = convert(data)\n",
    "\n",
    "if os.path.exists(data_random_order_json):\n",
    "    idxs = json.load(open(data_random_order_json))\n",
    "else:\n",
    "    idxs = list(range(len(data)))\n",
    "    np.random.shuffle(idxs)\n",
    "    json.dump(idxs, open(data_random_order_json, 'w'))\n",
    "\n",
    "data = [data[i] for i in idxs]\n",
    "\n",
    "with open(data_extract_json, 'w', encoding='utf-8') as f:\n",
    "    for d in data:\n",
    "        f.write(json.dumps(d, ensure_ascii=False, cls=NpEncoder) + '\\n')\n",
    "\n",
    "print(u'输入数据：%s' % data_json)\n",
    "print(u'数据顺序：%s' % data_random_order_json)\n",
    "print(u'输出路径：%s' % data_extract_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转换特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection\n",
    "from transformers import *\n",
    "from tokenizers import BertWordPieceTokenizer, ByteLevelBPETokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import initializers, activations\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from typing import Dict, List, Optional, Union\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "Some weights or buffers of the PyTorch model TFBertModel were not initialized from the TF 2.0 model and are newly initialized: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = '/root/zhengyanzhao/comment/emotion/model/'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_path)\n",
    "config = BertConfig.from_json_file(config_path)\n",
    "config.output_hidden_states = True\n",
    "bert_model = TFBertModel.from_pretrained(pretrained_path,config=config,from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"加载数据\n",
    "    返回：[texts]\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    with open(filename) as f:\n",
    "        for l in f:\n",
    "            texts = json.loads(l)[0]\n",
    "            D.append(texts)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = load_data('./sfzy_small_extract.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pooling  = tf.keras.layers.GlobalAveragePooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_token(texts):\n",
    "    token_ = []\n",
    "    for text in tqdm(texts,desc='转换向量'):\n",
    "        token = tokenizer(text,max_length=256,truncation=True,padding=True,return_tensors=\"tf\")\n",
    "        vecotor = bert_model(token)[0]\n",
    "        pooling = average_pooling(vecotor,mask=token['attention_mask'])\n",
    "        token_.append(pooling)\n",
    "    return token_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换向量: 100%|██████████| 4047/4047 [1:21:20<00:00,  1.21s/it]  \n"
     ]
    }
   ],
   "source": [
    "pooling =  conver_token(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('vector_exteact', pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_padding(inputs, length=None, padding=0, mode='post'):\n",
    "    \"\"\"Numpy函数，将序列padding到同一长度\n",
    "    \"\"\"\n",
    "    if length is None:\n",
    "        length = max([len(x) for x in inputs])\n",
    "\n",
    "    pad_width = [(0, 0) for _ in np.shape(inputs[0])]\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        x = x[:length]\n",
    "        if mode == 'post':\n",
    "            pad_width[0] = (0, length - len(x))\n",
    "        elif mode == 'pre':\n",
    "            pad_width[0] = (length - len(x), 0)\n",
    "        else:\n",
    "            raise ValueError('\"mode\" argument must be \"post\" or \"pre\".')\n",
    "        x = np.pad(x, pad_width, 'constant', constant_values=padding)\n",
    "        outputs.append(x)\n",
    "    return np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sequence_padding(pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('vector_exteact', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualGatedConv1D(tf.keras.layers.Layer):\n",
    "    \"\"\"门控卷积\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size, dilation_rate=1, **kwargs):\n",
    "        super(ResidualGatedConv1D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ResidualGatedConv1D, self).build(input_shape)\n",
    "        self.conv1d = tf.keras.layers.Conv1D(\n",
    "            filters=self.filters * 2,\n",
    "            kernel_size=self.kernel_size,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            padding='same',\n",
    "        )\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "        if self.filters != input_shape[-1]:\n",
    "            self.dense = tf.keras.layers.Dense(self.filters, use_bias=False)\n",
    "\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha', shape=[1], initializer='zeros'\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            inputs = inputs * mask[:, :, None]\n",
    "\n",
    "        outputs = self.conv1d(inputs)\n",
    "        # 2*filters 相当于两组filters来 一组*sigmoid(另一组)\n",
    "        gate = K.sigmoid(outputs[..., self.filters:])\n",
    "        outputs = outputs[..., :self.filters] * gate\n",
    "        outputs = self.layernorm(outputs)\n",
    "\n",
    "        if hasattr(self, 'dense'):\n",
    "            #用于对象是否包含对应的属性值\n",
    "            inputs = self.dense(inputs)\n",
    "\n",
    "        return inputs + self.alpha * outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_extract_model(max_len,input_size,hidden_size):\n",
    "    input_ = tf.keras.layers.Input((max_len,input_size))\n",
    "    x = tf.keras.layers.Masking()(input_)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(hidden_size, use_bias=False)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = ResidualGatedConv1D(hidden_size, 3, dilation_rate=1)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = ResidualGatedConv1D(hidden_size, 3, dilation_rate=2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = ResidualGatedConv1D(hidden_size, 3, dilation_rate=4)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = ResidualGatedConv1D(hidden_size, 3, dilation_rate=8)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = ResidualGatedConv1D(hidden_size, 3, dilation_rate=1)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = ResidualGatedConv1D(hidden_size, 3, dilation_rate=1)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    out_put = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_, outputs=out_put)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,data,data_x,threshold=0.2):\n",
    "    '''\n",
    "    data : [sample_num,3,…]\n",
    "    0:spilt_text\n",
    "    1:label\n",
    "    2:summary_text\n",
    "    '''\n",
    "    evaluater = 0\n",
    "    pred = model.predict(data_x)[:,:,0]\n",
    "    # [sample_num,256]\n",
    "    for d,yp in tqdm(zip(data,pred),desc='evaluating'):\n",
    "        yp = yp[:len(d[0])]\n",
    "        yp = np.where(yp > threshold)[0]\n",
    "        pred_sum = ''.join([d[0][i] for i in yp])\n",
    "        evaluater += compute_main_metric(pred_sum,d[2],'token')\n",
    "    return evaluater/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(tf.keras.callbacks.Callback):\n",
    "    \"\"\"训练回调\n",
    "    \"\"\"\n",
    "    def __init__(self,threshold,valid_data,valid_x,fold):\n",
    "        self.best_metric = 0.0\n",
    "        self.threshold = threshold\n",
    "        self.valid_data = valid_data\n",
    "        self.valid_x = valid_x\n",
    "        self.fold = fold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        eva = evaluate(self.model,self.valid_data, self.valid_x, self.threshold + 0.1)\n",
    "        if  eva >= self.best_metric:  # 保存最优\n",
    "            self.best_metric = eva\n",
    "            self.model.save_weights('weights/extract_model_%s.hdf5' % self.fold)\n",
    "            print('eva raise to %s'%eva)\n",
    "        else:\n",
    "            print('eva is %s,not raise'%eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, fold, num_folds, mode):\n",
    "    \"\"\"划分训练集和验证集\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        D = [d for i, d in enumerate(data) if i % num_folds != fold]\n",
    "    else:\n",
    "        D = [d for i, d in enumerate(data) if i % num_folds == fold]\n",
    "\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return np.array(D)\n",
    "    else:\n",
    "        return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 768\n",
    "hidden_size = 384\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "threshold = 0.2\n",
    "num_folds = 15\n",
    "max_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = bulid_extract_model(max_len,input_size,hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 768)]        0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 256, 768)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 768)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256, 384)          294912    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "residual_gated_conv1d (Resid (None, 256, 384)          886273    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "residual_gated_conv1d_1 (Res (None, 256, 384)          886273    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "residual_gated_conv1d_2 (Res (None, 256, 384)          886273    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "residual_gated_conv1d_3 (Res (None, 256, 384)          886273    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "residual_gated_conv1d_4 (Res (None, 256, 384)          886273    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "residual_gated_conv1d_5 (Res (None, 256, 384)          886273    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256, 384)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256, 1)            385       \n",
      "=================================================================\n",
      "Total params: 5,612,935\n",
      "Trainable params: 5,612,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"加载数据\n",
    "    返回：[(texts, labels, summary)]\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    with open(filename) as f:\n",
    "        for l in f:\n",
    "            D.append(json.loads(l))\n",
    "    return D\n",
    "\n",
    "data = load_data('sfzy_small_extract.json')\n",
    "data_x = np.load('vector_exteact.npy')\n",
    "data_y = np.zeros_like(data_x[...,:1])\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    for j in d[1]:\n",
    "        data_y[i][j][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4047, 256, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4047, 256, 768)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3777 samples\n",
      "Epoch 1/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.8960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 3it [00:00, 26.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 7it [00:00, 28.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 12it [00:00, 32.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 16it [00:00, 31.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 20it [00:00, 17.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 23it [00:01, 18.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 29it [00:01, 22.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 33it [00:01, 24.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 38it [00:01, 28.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 42it [00:01, 29.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 46it [00:01, 29.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 50it [00:01, 32.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 54it [00:01, 33.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 58it [00:02, 34.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 62it [00:02, 35.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 66it [00:02, 34.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 70it [00:02, 35.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 74it [00:02, 34.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 78it [00:02, 35.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 83it [00:02, 33.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 87it [00:02, 29.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 91it [00:03, 30.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 95it [00:03, 31.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 99it [00:03, 30.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 104it [00:03, 33.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 108it [00:03, 28.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 112it [00:03, 27.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 117it [00:03, 31.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 121it [00:03, 32.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 127it [00:04, 36.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 134it [00:04, 41.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 140it [00:04, 42.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 145it [00:04, 33.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 149it [00:04, 32.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 155it [00:04, 36.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 159it [00:04, 34.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 163it [00:05, 33.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 167it [00:05, 32.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 171it [00:05, 32.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 175it [00:05, 30.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 179it [00:05, 32.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 184it [00:05, 35.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 191it [00:05, 41.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 196it [00:05, 40.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 201it [00:06, 39.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 207it [00:06, 39.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 212it [00:06, 35.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 216it [00:06, 30.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 220it [00:06, 28.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 224it [00:06, 28.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 227it [00:07, 25.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 232it [00:07, 27.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 239it [00:07, 33.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 244it [00:07, 36.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 249it [00:07, 34.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 253it [00:07, 35.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 257it [00:07, 35.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 261it [00:07, 31.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 265it [00:08, 30.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 270it [00:08, 33.01it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva raise to 0.4095275662767998\n",
      "3777/3777 [==============================] - 23s 6ms/sample - loss: 0.2001 - acc: 0.8960\n",
      "Epoch 2/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 5it [00:00, 41.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 11it [00:00, 45.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 16it [00:00, 45.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 20it [00:00, 32.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 25it [00:00, 34.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 29it [00:00, 33.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 35it [00:00, 37.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 39it [00:01, 37.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 44it [00:01, 39.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 50it [00:01, 43.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 55it [00:01, 43.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 62it [00:01, 48.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 68it [00:01, 50.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 74it [00:01, 51.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 80it [00:01, 52.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 86it [00:01, 49.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 92it [00:02, 51.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 99it [00:02, 52.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 105it [00:02, 52.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 113it [00:02, 56.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 119it [00:02, 54.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 127it [00:02, 58.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 134it [00:02, 56.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 141it [00:02, 56.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 147it [00:03, 47.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 153it [00:03, 46.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 158it [00:03, 46.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 163it [00:03, 45.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 168it [00:03, 39.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 173it [00:03, 39.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 178it [00:03, 40.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 183it [00:03, 38.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 189it [00:04, 42.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 195it [00:04, 44.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 200it [00:04, 41.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 208it [00:04, 46.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 214it [00:04, 47.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 220it [00:04, 48.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 226it [00:04, 47.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 232it [00:04, 49.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 242it [00:05, 56.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 249it [00:05, 57.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 256it [00:05, 54.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 262it [00:05, 49.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 270it [00:05, 48.24it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva is 0.3557240250182881,not raise\n",
      "3777/3777 [==============================] - 15s 4ms/sample - loss: 0.1489 - acc: 0.9146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 1it [00:01,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 3it [00:01,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 5it [00:01,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 7it [00:01,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 10it [00:01,  2.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 12it [00:02,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 14it [00:02,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 16it [00:02,  5.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 18it [00:02,  6.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 20it [00:03,  5.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 22it [00:03,  6.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 24it [00:03,  7.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 26it [00:03,  8.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 28it [00:03,  9.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 30it [00:03,  9.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 33it [00:04, 11.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 35it [00:04, 12.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 37it [00:04, 13.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 39it [00:04, 14.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 41it [00:04, 15.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 43it [00:04, 15.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 45it [00:04, 14.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 47it [00:04, 14.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 49it [00:05, 14.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 51it [00:05, 14.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 54it [00:05, 15.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 56it [00:05, 14.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 58it [00:05, 15.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 61it [00:05, 16.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 63it [00:06, 14.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 65it [00:06, 13.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 67it [00:06, 14.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 69it [00:06, 13.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 71it [00:06, 12.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 73it [00:06, 13.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 75it [00:06, 13.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 78it [00:07, 14.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 80it [00:07, 15.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 82it [00:07, 16.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 84it [00:07, 12.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 86it [00:07, 13.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 89it [00:07, 15.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 91it [00:08, 11.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 93it [00:08, 12.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 95it [00:08, 12.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 97it [00:08, 12.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 99it [00:08, 12.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 102it [00:08, 14.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 104it [00:09, 13.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 106it [00:09, 10.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 108it [00:09, 11.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 110it [00:09, 12.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 112it [00:09, 12.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 114it [00:09, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 116it [00:10, 12.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 118it [00:10, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 120it [00:10, 14.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 122it [00:10, 15.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 124it [00:10, 15.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 126it [00:10, 16.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 128it [00:10, 15.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 130it [00:10, 15.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 132it [00:11, 15.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 134it [00:11, 16.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 137it [00:11, 18.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 139it [00:11, 15.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 141it [00:11, 14.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 143it [00:11, 12.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 145it [00:11, 13.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 147it [00:12, 13.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 149it [00:12, 12.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 151it [00:12, 11.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 153it [00:12, 12.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 155it [00:12, 13.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 157it [00:12, 12.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 159it [00:13, 11.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 161it [00:13, 11.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 163it [00:13, 12.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 165it [00:13, 13.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 167it [00:13, 11.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 169it [00:13, 10.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 171it [00:14, 10.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 173it [00:14, 11.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 175it [00:14, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 177it [00:14, 11.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 179it [00:14, 11.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 181it [00:14, 13.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 183it [00:15, 11.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 185it [00:15, 13.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 187it [00:15, 14.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 189it [00:15, 15.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 192it [00:15, 17.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 195it [00:15, 19.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 198it [00:15, 17.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 200it [00:16, 16.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 202it [00:16, 16.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 205it [00:16, 17.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 207it [00:16, 17.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 209it [00:16, 16.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 211it [00:16, 15.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 213it [00:16, 12.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 215it [00:17, 12.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 217it [00:17, 14.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 219it [00:17, 13.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 221it [00:17, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 223it [00:17, 11.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 226it [00:17, 13.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 229it [00:18, 13.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 232it [00:18, 14.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 235it [00:18, 16.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 237it [00:18, 16.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 239it [00:18, 17.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 241it [00:18, 17.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 243it [00:18, 16.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 245it [00:19, 15.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 247it [00:19, 16.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 250it [00:19, 17.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 252it [00:19, 14.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 255it [00:19, 15.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 257it [00:19, 16.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 259it [00:19, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 261it [00:20, 13.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 263it [00:20, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 265it [00:20, 11.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 268it [00:20, 13.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 270it [00:20, 13.01it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva raise to 0.5717615694112914\n",
      "3777/3777 [==============================] - 30s 8ms/sample - loss: 0.1384 - acc: 0.9196\n",
      "Epoch 4/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 2it [00:00, 12.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 5it [00:00, 13.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 7it [00:00, 14.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 10it [00:00, 16.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 12it [00:00, 15.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 14it [00:00, 15.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 16it [00:00, 15.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 18it [00:01, 15.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 20it [00:01, 11.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 22it [00:01, 12.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 24it [00:01, 13.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 26it [00:01, 14.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 29it [00:01, 14.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 31it [00:02, 14.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 33it [00:02, 15.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 35it [00:02, 15.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 37it [00:02, 15.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 39it [00:02, 16.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 41it [00:02, 17.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 43it [00:02, 17.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 45it [00:02, 16.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 47it [00:03, 15.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 49it [00:03, 15.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 51it [00:03, 16.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 54it [00:03, 17.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 56it [00:03, 16.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 58it [00:03, 17.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 61it [00:03, 18.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 63it [00:03, 17.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 65it [00:04, 16.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 68it [00:04, 17.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 70it [00:04, 15.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 72it [00:04, 13.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 75it [00:04, 14.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 78it [00:04, 15.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 80it [00:05, 16.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 83it [00:05, 15.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 85it [00:05, 15.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 88it [00:05, 17.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 90it [00:05, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 92it [00:05, 14.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 94it [00:05, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 96it [00:06, 13.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 98it [00:06, 14.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 101it [00:06, 15.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 103it [00:06, 16.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 105it [00:06, 13.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 107it [00:06, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 110it [00:07, 14.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 112it [00:07, 15.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 114it [00:07, 15.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 116it [00:07, 14.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 118it [00:07, 15.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 121it [00:07, 16.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 123it [00:07, 16.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 125it [00:07, 16.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 128it [00:08, 17.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 131it [00:08, 18.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 134it [00:08, 18.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 137it [00:08, 21.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 140it [00:08, 18.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 142it [00:08, 15.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 144it [00:09, 14.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 146it [00:09, 15.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 148it [00:09, 14.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 150it [00:09, 14.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 152it [00:09, 14.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 155it [00:09, 16.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 157it [00:09, 15.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 159it [00:09, 15.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 161it [00:10, 14.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 164it [00:10, 15.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 166it [00:10, 13.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 168it [00:10, 13.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 171it [00:10, 13.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 173it [00:10, 14.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 175it [00:11, 13.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 177it [00:11, 14.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 179it [00:11, 14.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 181it [00:11, 14.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 183it [00:11, 13.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 186it [00:11, 15.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 189it [00:11, 16.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 191it [00:12, 16.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 194it [00:12, 18.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 196it [00:12, 17.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 198it [00:12, 15.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 200it [00:12, 16.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 202it [00:12, 17.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 205it [00:12, 17.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 207it [00:13, 16.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 209it [00:13, 15.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 211it [00:13, 14.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 213it [00:13, 13.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 215it [00:13, 13.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 218it [00:13, 13.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 221it [00:13, 15.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 223it [00:14, 13.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 226it [00:14, 14.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 229it [00:14, 15.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 232it [00:14, 16.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 235it [00:14, 17.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 238it [00:14, 19.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 241it [00:15, 18.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 243it [00:15, 18.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 245it [00:15, 17.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 248it [00:15, 18.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 250it [00:15, 18.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 252it [00:15, 16.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 254it [00:15, 17.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 257it [00:16, 17.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 259it [00:16, 15.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 261it [00:16, 15.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 263it [00:16, 15.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 265it [00:16, 12.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 270it [00:16, 16.02it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva raise to 0.5728772715559592\n",
      "3777/3777 [==============================] - 26s 7ms/sample - loss: 0.1288 - acc: 0.9236\n",
      "Epoch 5/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 2it [00:00, 11.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 5it [00:00, 12.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 7it [00:00, 13.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 10it [00:00, 15.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 12it [00:00, 14.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 14it [00:00, 14.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 16it [00:01, 14.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 18it [00:01, 14.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 20it [00:01,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 22it [00:01, 11.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 24it [00:01, 12.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 26it [00:01, 13.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 29it [00:02, 13.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 31it [00:02, 13.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 33it [00:02, 14.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 35it [00:02, 15.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 37it [00:02, 15.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 39it [00:02, 15.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 41it [00:02, 15.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 43it [00:03, 15.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 45it [00:03, 14.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 47it [00:03, 14.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 49it [00:03, 15.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 51it [00:03, 16.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 54it [00:03, 17.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 56it [00:03, 16.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 59it [00:03, 17.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 61it [00:04, 16.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 63it [00:04, 16.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 65it [00:04, 16.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 67it [00:04, 17.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 69it [00:04, 14.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 71it [00:04, 13.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 74it [00:04, 14.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 76it [00:05, 14.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 78it [00:05, 15.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 80it [00:05, 16.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 83it [00:05, 15.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 85it [00:05, 15.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 88it [00:05, 16.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 90it [00:06, 12.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 92it [00:06, 13.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 94it [00:06, 13.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 96it [00:06, 13.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 98it [00:06, 14.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 101it [00:06, 15.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 103it [00:06, 16.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 105it [00:07, 13.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 107it [00:07, 13.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 110it [00:07, 14.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 112it [00:07, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 114it [00:07, 14.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 116it [00:07, 13.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 118it [00:07, 14.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 120it [00:08, 15.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 122it [00:08, 15.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 124it [00:08, 14.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 127it [00:08, 16.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 129it [00:08, 16.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 132it [00:08, 16.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 134it [00:08, 17.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 137it [00:09, 18.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 139it [00:09, 16.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 141it [00:09, 15.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 143it [00:09, 13.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 146it [00:09, 14.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 148it [00:09, 14.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 150it [00:09, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 152it [00:10, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 155it [00:10, 15.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 157it [00:10, 15.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 159it [00:10, 13.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 161it [00:10, 12.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 164it [00:10, 14.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 166it [00:11, 12.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 168it [00:11, 12.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 170it [00:11, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 172it [00:11, 12.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 174it [00:11, 13.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 176it [00:11, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 178it [00:11, 14.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 180it [00:12, 15.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 182it [00:12, 13.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 184it [00:12, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 187it [00:12, 16.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 190it [00:12, 17.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 192it [00:12, 16.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 195it [00:12, 18.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 198it [00:13, 17.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 201it [00:13, 18.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 203it [00:13, 17.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 206it [00:13, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 209it [00:13, 17.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 211it [00:13, 17.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 213it [00:13, 15.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 215it [00:14, 14.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 217it [00:14, 15.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 219it [00:14, 14.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 221it [00:14, 16.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 223it [00:14, 13.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 226it [00:14, 14.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 229it [00:15, 14.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 232it [00:15, 15.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 235it [00:15, 17.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 237it [00:15, 16.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 239it [00:15, 16.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 241it [00:15, 17.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 243it [00:15, 17.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 245it [00:15, 17.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 248it [00:16, 17.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 251it [00:16, 17.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 253it [00:16, 17.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 255it [00:16, 18.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 258it [00:16, 17.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 260it [00:16, 15.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 262it [00:16, 16.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 264it [00:17, 15.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 266it [00:17, 14.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 270it [00:17, 15.52it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva raise to 0.5786838417444797\n",
      "3777/3777 [==============================] - 27s 7ms/sample - loss: 0.1246 - acc: 0.9255\n",
      "Epoch 6/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 2it [00:00, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 5it [00:00, 11.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 7it [00:00, 12.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 9it [00:00, 14.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 11it [00:00, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 13it [00:00, 14.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 15it [00:01, 15.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 17it [00:01, 14.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 19it [00:01, 15.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 21it [00:01,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 23it [00:01,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 25it [00:01, 11.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 27it [00:02, 11.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 29it [00:02, 11.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 31it [00:02, 12.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 33it [00:02, 13.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 35it [00:02, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 37it [00:02, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 39it [00:02, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 41it [00:03, 14.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 43it [00:03, 15.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 45it [00:03, 14.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 47it [00:03, 14.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 49it [00:03, 14.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 51it [00:03, 15.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 54it [00:03, 17.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 56it [00:04, 16.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 58it [00:04, 16.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 61it [00:04, 17.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 63it [00:04, 14.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 65it [00:04, 15.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 67it [00:04, 15.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 69it [00:04, 13.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 71it [00:05, 12.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 73it [00:05, 13.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 75it [00:05, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 77it [00:05, 15.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 79it [00:05, 15.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 81it [00:05, 15.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 83it [00:05, 14.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 85it [00:05, 14.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 87it [00:06, 15.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 89it [00:06, 16.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 91it [00:06, 11.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 93it [00:06, 12.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 95it [00:06, 11.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 98it [00:07, 12.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 100it [00:07, 12.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 102it [00:07, 12.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 104it [00:07, 11.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 106it [00:07, 10.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 108it [00:07, 12.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 110it [00:07, 13.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 112it [00:08, 13.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 114it [00:08, 14.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 116it [00:08, 14.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 118it [00:08, 14.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 120it [00:08, 15.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 122it [00:08, 15.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 124it [00:08, 14.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 126it [00:09, 14.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 128it [00:09, 14.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 130it [00:09, 15.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 132it [00:09, 14.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 134it [00:09, 15.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 136it [00:09, 16.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 138it [00:09, 16.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 140it [00:10, 13.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 142it [00:10, 11.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 144it [00:10, 10.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 146it [00:10, 11.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 148it [00:10, 12.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 150it [00:10, 12.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 152it [00:11, 13.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 155it [00:11, 14.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 157it [00:11, 13.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 159it [00:11, 12.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 161it [00:11, 11.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 164it [00:11, 13.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 166it [00:12, 11.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 168it [00:12, 12.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 170it [00:12, 12.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 172it [00:12, 10.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 174it [00:12, 11.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 176it [00:12, 11.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 178it [00:13, 11.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 180it [00:13, 12.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 182it [00:13, 11.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 184it [00:13, 12.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 187it [00:13, 14.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 190it [00:13, 15.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 192it [00:14, 16.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 195it [00:14, 18.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 198it [00:14, 17.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 201it [00:14, 18.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 203it [00:14, 16.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 206it [00:14, 17.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 208it [00:14, 16.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 210it [00:15, 16.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 212it [00:15, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 214it [00:15, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 216it [00:15, 13.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 218it [00:15, 13.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 221it [00:15, 15.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 223it [00:15, 13.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 226it [00:16, 14.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 229it [00:16, 14.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 232it [00:16, 15.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 235it [00:16, 16.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 237it [00:16, 16.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 239it [00:16, 17.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 241it [00:17, 16.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 243it [00:17, 16.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 245it [00:17, 14.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 247it [00:17, 15.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 249it [00:17, 16.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 251it [00:17, 14.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 253it [00:17, 14.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 255it [00:17, 15.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 257it [00:18, 15.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 259it [00:18, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 261it [00:18, 13.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 263it [00:18, 14.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 265it [00:18, 11.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 267it [00:18, 12.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 270it [00:19, 14.13it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva raise to 0.5928227877196184\n",
      "3777/3777 [==============================] - 28s 8ms/sample - loss: 0.1218 - acc: 0.9267\n",
      "Epoch 7/20\n",
      "3776/3777 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 1it [00:00,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 2it [00:00,  8.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 5it [00:00,  9.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 7it [00:00, 10.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 9it [00:00, 11.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 11it [00:00, 11.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 13it [00:01, 11.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 15it [00:01, 12.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 17it [00:01, 12.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 19it [00:01, 12.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 21it [00:01,  8.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 23it [00:02,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 25it [00:02, 10.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 27it [00:02, 10.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 29it [00:02, 10.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 31it [00:02, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 33it [00:03, 10.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 35it [00:03, 10.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "evaluating: 37it [00:03, 10.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d0b8f3fe1ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m                       total_epochs=1)\n\u001b[1;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 372\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-4bd9830feae1>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0meva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m  \u001b[0meva\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_metric\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 保存最优\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-dc7a4666421f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data, data_x, threshold)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpred_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mevaluater\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompute_main_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mevaluater\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-00e27284ce1f>\u001b[0m in \u001b[0;36mcompute_main_metric\u001b[0;34m(source, target, unit)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"计算所有metrics\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_rouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     metrics['main'] = (\n\u001b[1;32m     34\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-00e27284ce1f>\u001b[0m in \u001b[0;36mcompute_rouge\u001b[0;34m(source, target, unit)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         return {\n\u001b[1;32m     18\u001b[0m             \u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m_get_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mraw_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     exclusive=self.exclusive)\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0msen_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hyp, ref, **k)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;34m\"rouge-2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"rouge-l\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mrouge_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_l_summary_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     }\n\u001b[1;32m     58\u001b[0m     \u001b[0mDEFAULT_STATS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36mrouge_l_summary_level\u001b[0;34m(evaluated_sentences, reference_sentences, raw_results, exclusive, **_)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                       \u001b[0mref_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                       \u001b[0mprev_union\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                       exclusive=exclusive)\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0munion_lcs_sum_across_all_references\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlcs_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36m_union_lcs\u001b[0;34m(evaluated_sentences, reference_sentence, prev_union, exclusive)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meval_s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluated_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mevaluated_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_into_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_s\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mlcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_recon_lcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluated_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclusive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mcombined_lcs_length\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mlcs_union\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcs_union\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36m_recon_lcs\u001b[0;34m(x, y, exclusive)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.7/site-packages/rouge/rouge_score.py\u001b[0m in \u001b[0;36m_lcs\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "evaluating: 37it [00:23, 10.86it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "for fold in range(num_folds):\n",
    "    train_data = data_split(data, fold, num_folds, 'train')\n",
    "    valid_data = data_split(data, fold, num_folds, 'valid')\n",
    "    train_x = data_split(data_x, fold, num_folds, 'train')\n",
    "    valid_x = data_split(data_x, fold, num_folds, 'valid')\n",
    "    train_y = data_split(data_y, fold, num_folds, 'train')\n",
    "    valid_y = data_split(data_y, fold, num_folds, 'valid')\n",
    "    # 启动训练\n",
    "    evaluator = Evaluator(threshold,valid_data,valid_x,fold)\n",
    "    model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[evaluator]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
